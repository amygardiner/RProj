---
title: "assignment_5"
author: "Amy Gardiner"
date: "26/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr) 
library(ggplot2)
library(tidyverse)
```

## Expectation and variance of a discrete random variable

Suppose that α,β ∈ [0,1] with α+β ≤ 1 and let X be a discrete random variable with with distribution supported on {0, 1, 5}. Suppose that P (X = 1) = α and P (X = 5) = β and P (X ∈/ {0, 1, 5}) = 0.
What is the probability mass function pX : S → [0,1] for X?

pX = α if X=1\
   = β if X=5\
   = 1-α-β if X=0\
   = 0 if X ∈/ {0, 1, 5}
   
The expectation is α + 5β

The variance is sum(pX.(x-(α + 5β))^2) = β(5-(α + 5β))^2 + α (1-(α + 5β))^2) (can expand if necessary)

## Simulating data with the uniform distribution

```{r}
set.seed(0)
n<-1000
sample_X<-data.frame(U=runif(n))%>%
  mutate(X=case_when(
    (0<=U)&(U<0.25)~1,
    (0.25<=U)&(U<0.5)~5,
    (0.5<=U)&(U<=1)~0))%>%
pull(X)

head(sample_X,400)

sample_X_015<-function(alpha,beta,n){
  data.frame(U=runif(n))%>%
  mutate(X=case_when(
    (0<=U)&(U<alpha)~1,
    (alpha<=U)&(U<alpha+beta)~5,
    (alpha+beta<=U)&(U<=1)~0))%>%
  pull(X) 
}

test<-sample_X_015(0.5,0.1,100000)

head(test,400)

sample_avg<-mean(test)
sample_avg
```

Comparing this with the expectation E = 1(0.5)+5(0.1) = 1 this shows the impact of the law of large numbers.

Now use a range of beta values and compare the sample average:

```{r}
range<-seq(0,0.9,0.01)
average_vector<-c()

for(i in range){
  sample<-sample_X_015(0.1,i,100)
  sample_avg<-mean(sample)
  average_vector<-c(average_vector,sample_avg)
}


ggplot()+xlab("Value of Beta")+geom_line(aes(x=range,y=average_vector))+ylab("Sample Average")
  
```

## Gaussian Distribution

For a Gaussian with mean $\mu$ and standard deviation $\sigma$ > 0
the probability density function is:

f~$\mu$,$\sigma$~(x) := $\frac{1}{ \sigma sqrt2\pi}$ * exp(-1/2*((x-$ \mu $)/$ \sigma $))^2)

```{r}
range<-seq(-4,6,0.01)
plot_1<-dnorm(range,mean=1,sd=1,log=FALSE)
plot_2<-dnorm(range,mean=1,sd=sqrt(2),log=FALSE)
plot_3<-dnorm(range,mean=1,sd=sqrt(3),log=FALSE)
lp<-ggplot()+xlab("x")+geom_line(aes(x=range,y=plot_1,color="red",linetype='solid'))+geom_line(aes(x=range,y=plot_2,color="green",linetype='dashed'))+geom_line(aes(x=range,y=plot_3,color="blue",linetype='longdash'))+ylab("Density")

lp + scale_color_manual(values=c("blue","green","red"),
                       name="Variance",
                       labels=c("3","2","1"))
```

Corresponding plot for the cumulative distribution function:

```{r}
cplot_1<-pnorm(range,mean=1,sd=1,lower.tail=TRUE,log.p=FALSE)
cplot_2<-pnorm(range,mean=1,sd=sqrt(2),lower.tail=TRUE,log.p=FALSE)
cplot_3<-pnorm(range,mean=1,sd=sqrt(3),lower.tail=TRUE,log.p=FALSE)

clp<-ggplot()+xlab("x")+geom_line(aes(x=range,y=cplot_1,color="red",linetype='solid'))+geom_line(aes(x=range,y=cplot_2,color="green",linetype='dashed'))+geom_line(aes(x=range,y=cplot_3,color="blue",linetype='longdash'))+ylab("Density")

clp + scale_colour_manual(values=c("blue","green","red"),
                       name="Variance",
                       labels=c("3","2","1"))
```

The quantile function allows your to find the quantile (percentage) Q for any probability p. Hence, the qnorm function is the inverse of the pnorm function.

```{r}
qplot_1<-qnorm(cplot_1,mean=1,sd=1,lower.tail=TRUE,log.p=FALSE)
qplot_2<-qnorm(cplot_1,mean=1,sd=sqrt(2),lower.tail=TRUE,log.p=FALSE)
qplot_3<-qnorm(cplot_1,mean=1,sd=sqrt(3),lower.tail=TRUE,log.p=FALSE)

ggplot()+geom_line(aes(x=cplot_1,y=qplot_1))+geom_line(aes(x=cplot_2,y=qplot_2))+geom_line(aes(x=cplot_3,y=qplot_3))+xlab("Probability p")+ylab("Q(p)")
```

The rnorm function generates n observations from the Normal distribution with mean $\mu$ and variance $\sigma$^2. 

Linear transformation from independent and identically distributed sequence Z~1~,...,Z~n~ where Z is normally distributed with mean, variance 0,1 to an i.i.d sample of form Y~1~,...,Y~n~ where Y has mean, variance 1,3 is such that:\

Y~i~ = $\alpha$ * Z~i~ + $\beta$ \
where $\alpha$ is the variance and $\beta$ is the mean

```{r}
set.seed(1)
standardGuassianSample<-c(rnorm(100))
mean1Var3GaussianSampleA<-map_dbl(.x=standardGuassianSample,~.x*3+1)

set.seed(1)
mean1Var3GuassianSampleB<-c(rnorm(100,1,3))

standardGuassianSample
mean1Var3GaussianSampleA
mean1Var3GuassianSampleB

pop_plot<-dnorm(range,mean=1,sd=sqrt(3),log=FALSE)

kernal_plot<-ggplot()+geom_density(aes(x=mean1Var3GaussianSampleA),color="blue")+geom_line(aes(x=range,y=pop_plot,color="red"))+xlab("x")+ylab("Density")
kernal_plot
```

## The Binomial distribution and the central limit theorem

```{r}
set.seed(1)
x<-seq(0,50,1)
binom_df<-data.frame(x)
binom_df<-binom_df%>%
  mutate(pmf=dbinom(x,size=50,prob=0.7))

head(binom_df,3)
```

For binomial distribution with n trials and success probability p, mean $\mu$=np and sd $\sigma$=sqrt(np*(1-p))

```{r}
set.seed(1)
x<-seq(0,50,0.01)
norm_df<-data.frame(x)
norm_df<-norm_df%>%
  mutate(pdf=dnorm(x,35,sqrt(35*0.3)))

head(norm_df,3)
```

